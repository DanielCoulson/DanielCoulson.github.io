---
layout: archive
title: "PhD projects"
permalink: /research/
---

<h2>Boltzmann convolutions and Welford mean-variance layers with an application to time series forecasting and classification</h2>
<p>In this paper we propose a novel problem called the ForeClassing problem where the loss of a classification decision is only observed at a future time point after the classification decision has to be made. To solve this problem, we propose an approximately Bayesian deep neural network architecture called ForeClassNet for time series forecasting and classification. This network architecture forces the network to consider possible future realizations of the time series, by forecasting future time points and their likelihood of occurring, before making its final classification decision. To facilitate this, we introduce two novel neural network layers, Welford mean-variance layers and Boltzmann convolutional layers. Welford mean-variance layers allow networks to iteratively update their estimates of the mean and variance for the forecasted time points for each inputted time series to the network through successive forward passes, which the model can then consider in combination with a learned representation of the observed realizations of the time series for its classification decision. Boltzmann convolutional layers are linear combinations of approximately Bayesian convolutional layers with different filter lengths, allowing the model to learn multitemporal resolution representations of the input time series, and which resolutions to focus on within a given Boltzmann convolutional layer through a Boltzmann distribution. Both layers are novel additions to the deep learning practitioners' tool kit, which would be helpful in problems concerned with using neural networks to make decisions with sequential data regarding future events. Through several simulation scenarios and two real world applications we demonstrate ForeClassNet achieves superior performance compared with current state of the art methods including a near 30% improvement in test set accuracy in our financial example compared to the second best performing model.</p>
<p>Code: <a href="/files/ForeClassNet.zip" download>here</a></p>
<h2>A Bayesian factor model with dynamic shrinkage for time-varying correlation matrices with an application to Financial Crises</h2>
<p>In this paper we propose a novel approach to quantifying the risk from a co-movement of stocks in a portfolio through time, derived from time varying model-based correlation matrices. The correlation matrices are estimated in a Bayesian fashion utilizing a dynamic shrinkage prior process for the state variables to be estimated and a multivariate factor stochastic volatility process for the observation error covariance matrices. To summarize the information in correlation matrices we create an intuitive and simple scalar score. Through a simulation study we demonstrate our estimation approach achieves superior performance in terms of several metrics and has an ability to rapidly adapt to changing market conditions compared to competing methods. Through real world examples we demonstrate the new insights provided by our proposed framework in identifying known periods of financial instability and the additional information it provides beyond existing measures such as the VIX index. We subsequently compare the static minimum variance portfolio to that of a dynamically changing minimum variance portfolio in times of financial crisis. Our model provides a new overall measure of correlation in a system which can be utilized by both practitioners and researchers as a tool to quantify the correlation risks in a portfolio and the degree of toxicity in the financial system.</p>

<p>For more details, you can view the draft of the paper <a href="/files/PhD_Project_1.pdf" target="_blank">here</a>.</p>
